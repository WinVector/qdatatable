---
title: "Parallel rqdatatable"
author: "John Mount"
date: "`r Sys.Date()`"
output: github_document
---

One can try to execute [`rquery`](https://github.com/WinVector/rquery) `relop` trees in parallel using [`rqdatatable`](https://github.com/WinVector/rqdatatable). However, unless the pipeline is very expensive
the overhead of partitioning and distributing the work will usually overwhelm any parallel speedup.
Also `data.table` itself already seems to exploit some thread-level parallelism (notice user time > elapsed time).

That being said, we can test an example where computation is expensive due to a blow-up in an intermediate join step.

Set up our execution environment and example (some details: OSX 10.13.4 on a 2.8 GHz Intel Core i5 Mac Mini (Late 2015 model) with 8GB ram and hybrid disk drive).

```{r ex}
library("rqdatatable")
library("microbenchmark")
library("ggplot2")
library("WVPlots")
library("dplyr")

base::date()
R.version.string
parallel::detectCores()
packageVersion("parallel")
packageVersion("rqdatatable")
packageVersion("rquery")
packageVersion("dplyr")


cl <- parallel::makeCluster(4)
#parallel::clusterEvalQ(cl, library("rquery"))
#parallel::clusterEvalQ(cl, library("rqdatatable"))


set.seed(2362)
mk_example <- function(nkey, nrep, ngroup = 20) {
  keys <- paste0("key_", seq_len(nkey))
  key_group <- sample(as.character(seq_len(ngroup)), 
                      length(keys), replace = TRUE)
  names(key_group) <- keys
  key_table <- data.frame(
    key = rep(keys, nrep),
    stringsAsFactors = FALSE)
  key_table$data <- runif(nrow(key_table))
  instance_table <- data.frame(
    key = rep(keys, nrep),
    stringsAsFactors = FALSE)
  instance_table$id <- seq_len(nrow(instance_table))
  instance_table$info <- runif(nrow(instance_table))
  # groups should be no finer than keys
  key_table$key_group <- key_group[key_table$key]
  instance_table$key_group <- key_group[instance_table$key]
  list(key_table = key_table,
       instance_table = instance_table)
}

dlist <- mk_example(10, 10)
data <- dlist$instance_table
annotation <- dlist$key_table
```

[`rquery`](https://github.com/WinVector/rquery) and [`rqdatatable`](https://github.com/WinVector/rqdatatable) can operate a non-trivial operation tree as follows.

```{r rquery1}
# possible data lookup: find rows that
# have lookup data <= info
optree <- local_td(data) %.>%
  natural_join(., local_td(annotation), jointype = "INNER", by = "key") %.>%
  select_rows_nse(., data <= info) %.>%
  pick_top_k(., 
             k = 1,
             partitionby = "id",
             orderby = "data",
             reverse = "data",
             keep_order_column = FALSE) %.>%
  orderby(., "id")
cat(format(optree))


res1 <- ex_data_table(optree)
head(res1)
nrow(res1)
```

And we can execute the operations in parallel.

```{r rqdatatablep1}
parallel::clusterEvalQ(cl, library("rqdatatable"))
res2 <- ex_data_table_parallel(optree, "key_group", cl)
head(res2)
nrow(res2)
```

[`data.table`](http://r-datatable.com) can implement the same function.

```{r data_table_f}
library("data.table")

data_table_f <- function(data, annotation) {
  data <- data.table::as.data.table(data)
  annotation <- data.table::as.data.table(annotation)
  joined <- merge(data, annotation, by = "key", all=FALSE, allow.cartesian=TRUE)
  joined <- joined[joined$data <= joined$info, ]
  data.table::setorderv(joined, cols = "data")
  joined <- joined[, .SD[.N], id]
  data.table::setorderv(joined, cols = "id")
}
resdt <- data_table_f(data, annotation)
head(resdt)
nrow(resdt)
```

We can also run `data.table` in parallel using [`wrapr::execute_parallel`](https://winvector.github.io/wrapr/reference/execute_parallel.html).

```{r data_table_p}
parallel::clusterEvalQ(cl, library("data.table"))
parallel::clusterExport(cl, "data_table_f")

dt_f <- function(tables_list) {
  data <- tables_list$data
  annotation <- tables_list$annotation
  data_table_f(data, annotation)
}

data_table_parallel_f <- function(data, annotation) {
  respdt <- wrapr::execute_parallel(tables = list(data = data, annotation = annotation),
                                  f = dt_f,
                                  partition_column = "key_group",
                                  cl = cl) %.>%
  data.table::rbindlist(.)
  data.table::setorderv(respdt, cols = "id")
  respdt
}
respdt <- data_table_parallel_f(data, annotation)
head(respdt)
nrow(respdt)
```



[`dplyr`](https://CRAN.R-project.org/package=dplyr) can also implement the solution.

```{r dplyr1}
dplyr_pipeline <- function(data, annotation) {
  res <- data %>%
    inner_join(annotation, by = "key") %>%
    filter(data <= info) %>%
    group_by(id) %>%
    arrange(-data) %>%
    mutate(rownum = row_number()) %>%
    ungroup() %>%
    filter(rownum == 1) %>%
    arrange(id)
  res
}

resd <- dplyr_pipeline(data, annotation)
head(resd)
nrow(resd)
```

And we can use [`wrapr::execute_parallel`](https://winvector.github.io/wrapr/reference/execute_parallel.html) to
also parallelize the `dplyr` solution.

```{r dplyr_wp}
parallel::clusterEvalQ(cl, library("dplyr"))
parallel::clusterExport(cl, "dplyr_pipeline")

dplyr_f <- function(tables_list) {
  data <- tables_list$data
  annotation <- tables_list$annotation
  dplyr_pipeline(data, annotation)
}

dplyr_parallel_f <- function(data, annotation) {
  respdt <- wrapr::execute_parallel(tables = list(data = data, annotation = annotation),
                                  f = dplyr_f,
                                  partition_column = "key_group",
                                  cl = cl) %>%
    dplyr::bind_rows() %>%
    arrange(id)
}
respdplyr <- dplyr_parallel_f(data, annotation)
head(respdplyr)
nrow(respdplyr)
```


We can time the various realizations.

```{r, timings}
dlist <- mk_example(300, 300)
data <- dlist$instance_table
annotation <- dlist$key_table

timings <- microbenchmark(
  data_table_parallel = nrow(data_table_parallel_f(data, annotation)),
  data_table = nrow(data_table_f(data, annotation)),
  rqdatatable_parallel = nrow(ex_data_table_parallel(optree, "key_group", cl)),
  rqdatatable = nrow(ex_data_table(optree)),
  dplyr_parallel = nrow(dplyr_parallel_f(data, annotation)),
  dplyr = nrow(dplyr_pipeline(data, annotation)),
  times = 10L)

saveRDS(timings, "Parallel_rqdatatable_timings.RDS")
```

```{r present}
print(timings)

autoplot(timings)

timings <- as.data.frame(timings)
timings$seconds <- timings$time/1e+9

ScatterBoxPlotH(timings, 
                xvar = "seconds", yvar = "expr", 
                title="task duration by method")
```



[`multidplyr`](https://github.com/hadley/multidplyr) does not appear to work on this example,
so we could not include it in the timings.

```{r multidplyr, error=TRUE}
library("multidplyr") # https://github.com/hadley/multidplyr
packageVersion("multidplyr")
multidplyr::set_default_cluster(cl)

# example similar to https://github.com/hadley/multidplyr/blob/master/vignettes/multidplyr.Rmd
class(data)
datap <- multidplyr::partition(data, key_group)
head(datap)
class(datap)

class(annotation)
annotationp <- multidplyr::partition(annotation, key_group)
head(annotationp)
class(annotationp)

dplyr_pipeline(datap, annotationp) %>%
  collect()
```

[`dtplyr`](https://CRAN.R-project.org/package=dtplyr) does not appear to work on this example,
so we could not include it in the timings.

```{r dtplyr, error=TRUE}
library("data.table")
library("dtplyr") #  https://CRAN.R-project.org/package=dtplyr
packageVersion("data.table")
packageVersion("dtplyr")

class(data)
datadt <- data.table::as.data.table(data)
head(datadt)
class(datadt)

class(annotation)
annotationdt <- data.table::as.data.table(annotation)
head(annotationdt)
class(annotationdt)

dplyr_pipeline(datadt, annotationdt)
```

My theory is `dplyr` is seeing better scaling to processors because `dplyr` appears to be purely single threaded and `data.table` is multi-threaded (see for example `help("setDTthreads")`). `rqdatatable`'s performance regression relative to `datatable` I believe is from `rqdatatable`'s ranking strategy (something we will likely tune later, already [sometimes `rqdatatable` is competitive with `data.table` and actually quite fast](https://github.com/WinVector/rquery/blob/master/extras/data_table_replot.md)).



```{r cleanup}
parallel::stopCluster(cl)
rm(list = "cl")
```
