---
title: "Grouped Rank Filter"
output: github_document
---

Amazon EC2 `r4.8xlarge` (244 GiB RAM) run (8-12-2018, 64-bit Ubuntu Server 16.04 LTS (HVM), SSD Volume Type - ami-ba602bc2, R 3.4.4 all packages current).


```{r pythonsetup}
# https://cran.r-project.org/web/packages/reticulate/vignettes/r_markdown.html
library("reticulate")
use_python("/home/ruser/miniconda3/bin/python3")
# use_python("/Users/johnmount/anaconda3/bin/python3")
pandas_handle <- reticulate::import("pandas") # don't use as https://github.com/rstudio/reticulate/issues/319

pandas_fn <- py_run_string("
def py_fn(df):
   ord = df.sort_values(by = ['col_a', 'col_b', 'col_c', 'col_x'], ascending = [True, True, True, True])
   ord['rank_col'] = ord.groupby(['col_a', 'col_b', 'col_c']).cumcount()
   return ord[ord.rank_col == 0].ix[:, ['col_a', 'col_b', 'col_c', 'col_x']]
")
do_pandas <- function(d) {
  res <- pandas_fn$py_fn(pandas_handle$DataFrame(d))
  rownames(res) <- NULL
  return(res)
}
```


```{r setup}
library("rqdatatable")
library("microbenchmark")
library("ggplot2")
library("WVPlots")
library("cdata")
library("dplyr")
library("dtplyr")
library("data.table")

set.seed(32523)

mk_data <- function(nrow) {
  alphabet <- paste("sym", seq_len(max(2, floor(nrow^(1/3)))), sep = "_")
  data.frame(col_a = sample(alphabet, nrow, replace=TRUE),
             col_b = sample(alphabet, nrow, replace=TRUE),
             col_c = sample(alphabet, nrow, replace=TRUE),
             col_x = runif(nrow),
             stringsAsFactors = FALSE)
}
```


```{r def}
# adapted from help(microbenchmark)
my_check <- function(values) {
  values <- lapply(values,
                   function(vi) {
                     vi <- as.data.frame(vi)
                     rownames(vi) <- NULL
                     data.frame(vi) # strip attributes
                   })
  isTRUE(all(sapply(values[-1], function(x) identical(values[[1]], x))))
}
```

```{r dtplyr, error=TRUE}
ds <- mk_data(3)

ds %>%  
  group_by(col_a, col_b, col_c) %>% 
  arrange(col_x) %>% 
  filter(row_number() == 1) %>%
  ungroup() %>%
  arrange(col_a, col_b, col_c, col_x)

ds %>%  
  as.data.table() %>%
  group_by(col_a, col_b, col_c) %>% 
  arrange(col_x) %>% 
  filter(row_number() == 1) %>%
  ungroup() %>%
  arrange(col_a, col_b, col_c, col_x)
```

```{r baser}
shift_col <- function(col) { c(col[1], col[-length(col)]) }

base_r <- function(df) {
  rownames(df) <- NULL
  df <- df[order(df$col_a, df$col_b, df$col_c, df$col_x), , drop = FALSE]
  rownames(df) <- NULL
  first <- (df$col_a != shift_col(df$col_a)) | 
    (df$col_b != shift_col(df$col_b)) | 
    (df$col_c != shift_col(df$col_c))
  first[[1]] <- TRUE
  df <- df[first, , drop = FALSE]
  rownames(df) <- NULL
  df
}
```



```{r time}
pow <- 8
rds_name <- "GroupedRankFilter2_runs.RDS"
if(!file.exists(rds_name)) {
  szs <- expand.grid(a = c(1,2,5), b = 10^{0:pow}) 
  szs <- sort(unique(szs$a * szs$b))
  szs <- szs[szs<=10^pow]
  runs <- lapply(
    rev(szs),
    function(sz) {
      gc()
      d <- mk_data(sz)
      ti <- microbenchmark(
        base_r = {
          base_r(d)
        },
        data.table = { 
          # https://stackoverflow.com/questions/16325641/how-to-extract-the-first-n-rows-per-group
          d %.>% 
            as.data.table(.) %.>% 
            setorder(., col_a, col_b, col_c, col_x) %.>%
            .[, .SD[1], by=list(col_a, col_b, col_c)] 
        },
        rqdatatable = { 
          ops <- local_td(d) %.>%
            pick_top_k(., 
                       k = 1L,
                       orderby = "col_x",
                       partitionby = c("col_a", "col_b", "col_c"),
                       keep_order_column = FALSE) %.>%
            orderby(., c("col_a", "col_b", "col_c", "col_x"))
          d %.>% ops
        },
        dplyr = {
          d %>% 
            group_by(col_a, col_b, col_c) %>% 
            arrange(col_x) %>% 
            filter(row_number() == 1) %>%
            ungroup() %>%
            arrange(col_a, col_b, col_c, col_x)
        },
        dplyr_b = {
          d %>% 
            arrange(col_x) %>% 
            group_by(col_a, col_b, col_c) %>% 
            mutate(rn = row_number()) %>%
            ungroup() %>%
            filter(rn == 1) %>%
            select(col_a, col_b, col_c, col_x) %>%
            arrange(col_a, col_b, col_c, col_x)
        },
        pandas_reticulate = {
          do_pandas(d)
        },
        times = 3L,
        check = my_check)
      ti <- as.data.frame(ti)
      ti$rows <- sz
      ti
    })
  saveRDS(runs, rds_name)
} else {
  runs <- readRDS(rds_name)
}
```



```{r present, fig.retina=2, fig.width=12, fig.height=8}
timings <- do.call(rbind, runs)
timings$seconds <- timings$time/1e+9
timings$method <- factor(timings$expr,
                         levels = c("dplyr", "dplyr_b",
                                    "base_r", "pandas_reticulate",
                                    "rqdatatable", "data.table"))
method_map <- c(dplyr = "dplyr", 
                dplyr_b = "dplyr",
                pandas_reticulate = "base-R or R/python roundtrip",
                data.table =   "data.table",
                rqdatatable = "data.table",   
                base_r  = "base-R or R/python roundtrip")
timings$method_family <- method_map[as.character(timings$method)]
timings$method_family <- reorder(timings$method_family, -timings$seconds)
rowset <- sort(unique(timings$rows))
smooths <- lapply(
  unique(as.character(timings$method)),
  function(mi) {
    ti <- timings[timings$method == mi, , drop = FALSE]
    ti$rows <- log(ti$rows)
    si <- loess(log(seconds) ~ rows, data = ti)
    pi <- data.frame(
      method = mi,
      rows = log(rowset),
      stringsAsFactors = FALSE)
    pi$seconds <- exp(predict(si, newdata = pi))
    pi$rows <- rowset
    pi
  })
smooths <- do.call(rbind, smooths)
smooths$method <- factor(smooths$method, levels = levels(timings$method))

ggplot(data = timings, aes(x = rows, y = seconds)) +
  geom_line(data = smooths,
            alpha = 0.7,
            linetype = 2,
            aes(group = method, color = method)) +
  geom_point(data = timings, aes(color = method)) + 
  geom_smooth(data = timings, aes(color = method),
              se = FALSE, size = 2) +
  scale_x_log10() +
  scale_y_log10() +
  scale_color_manual(values = 
                       c("#1b9e77", "#d95f02",
                         "#7570b3", "#e7298a",
                         "#66a61e", "#e6ab02")) +
  ggtitle("grouped sorting task time by rows and method",
          subtitle = "log-log trend shown") +
  facet_wrap(~method_family, ncol=1, labeller = "label_both")

means <- timings %.>%
  project_nse(., 
              groupby = c("method", "rows"), 
              seconds = mean(seconds)) %.>%
  pivot_to_rowrecs(., 
                   columnToTakeKeysFrom = "method",
                   columnToTakeValuesFrom = "seconds",
                   rowKeyColumns = "rows") %.>%
  extend_nse(., 
             ratio = dplyr/data.table) %.>%
  orderby(., "rows")

knitr::kable(means)
  
ggplot(data = means, aes(x = rows, y = ratio)) +
  geom_point() + 
  geom_smooth(se = FALSE) +
  scale_x_log10() + 
  ggtitle("ratio of dplyr runtime to data.table runtime",
          subtitle = "grouped sorting/sum task")
```


